# 项目架构树状表与阶段总结报告

**生成时间**：2026-01-29 17:50 (UTC+8)
**当前进度**：第一、二、三阶段已全部完成 (✅ 100%)

---

## 1. 项目目录架构树 (Project Tree)

```text
GraduationProject/
├── 1.0/                      # 毕业设计前期准备文档
│   ├── 01_选题背景...        # 选题依据与数据背景
│   ├── 02_开题报告大纲...    # 论文架构与技术路线设计
│   └── ...                   # 其他建议报告与计划表
├── data/                     # 数据存储分层目录 (Git 忽略大数据文件)
│   ├── raw/                  # ODS层：原始 CSV 数据
│   ├── dwd/                  # DWD层：Parquet 分区清洗数据
│   └── ads/                  # ADS层：分析结果汇总数据
├── docs/                     # 项目核心文档库
│   ├── design/               # 架构与指标设计
│   │   ├── DATA_ARCHITECTURE.md  # 数仓四层架构定义
│   │   └── METRICS_DEFINITION.md # 业务指标计算口径
│   ├── guides/               # 环境与性能指南
│   ├── rules/                # 项目开发规范 (Git/代码/治理)
│   ├── summary/              # [当前目录] 阶段总结与架构报告
│   └── README.md             # 阶段性成果详细说明
├── logs/                     # 脚本运行历史日志
├── outputs/                  # 分析产出的 CSV/JSON 报表
├── .gitignore                # Git 忽略配置
├── README.md                 # 项目根目录总览
├── analysis_funnel.py        # 第三阶段：转化漏斗分析脚本
├── analysis_retention.py     # 第三阶段：留存分析脚本
├── analysis_rfm.py           # 第三阶段：RFM 用户分层脚本
├── benchmark_storage.py      # 第二阶段：存储性能对比实验脚本
├── data_dictionary.md        # 第一阶段：数据字典定义
├── data_quality_oct_2019.py  # 第一阶段：数据质量审计脚本
├── eda_oct_2019.py           # 第一阶段：探索性分析脚本
├── environment.yml           # Conda 环境配置文件
├── etl_dwd_user_behavior.py  # 第二阶段：DWD 层清洗 ETL 脚本
├── sample_data.py            # 第一阶段：数据采样脚本
└── test_spark.py             # 第一阶段：环境验证测试脚本
```

---

## 2. 核心文件内容说明表

| 文件/目录 | 阶段 | 对应内容与核心价值 |
| :--- | :--- | :--- |
| `1.0/` | 准备 | 存储毕业设计的理论支撑、开题大纲和导师建议。 |
| `docs/design/` | 2 & 3 | 存储数仓的“灵魂”——架构图和指标口径，确保开发不偏离业务。 |
| `data/dwd/` | 2 | 存储清洗后的 Parquet 数据，是整个分析系统的“发动机”。 |
| `data/ads/` | 3 | 存储漏斗、留存、RFM 的计算结果，直接对接可视化看板。 |
| `etl_dwd_...py` | 2 | 负责将杂乱的 CSV 转换为结构化、分区化的明细数据。 |
| `analysis_...py` | 3 | 负责执行复杂的业务逻辑计算（漏斗路径、Cohort矩阵、ML分层）。 |
| `benchmark_...py` | 2 | 提供论文中“性能优化”章节的实验数据（Parquet vs CSV）。 |
| `logs/` | 全 | 记录所有脚本的运行时间、数据量和错误信息，确保可追溯性。 |

---

## 3. 阶段性成果总结

1. **第一阶段 (100%)**: 完成了从“海量原始数据”到“可处理样本”的跨越，明确了数据质量边界。
2. **第二阶段 (100%)**: 建立了标准化的数仓底座，通过分区和列存技术将查询性能提升了 **44 倍**。
3. **第三阶段 (100%)**: 业务价值变现，成功从数据中提取出转化率、留存率和用户群体特征，为论文提供了核心论点。

---
*报告结束。本项目已准备好进入第四阶段：高级建模与优化。*
